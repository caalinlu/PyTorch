{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch实现手写数字识别.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caalinlu/PyTorch/blob/master/PyTorch%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqLFbWZdd_eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as t  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE5ea2SQjCFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_image(data):\n",
        "  data = data.view(-1, 1, 28, 28)\n",
        "  return data\n",
        "\n",
        "class fc_net(t.nn.Module):\n",
        "  \"\"\"\n",
        "  全连接网络\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(fc_net,self).__init__()\n",
        "    self.fc1 = t.nn.Sequential(t.nn.Linear(784, 200), t.nn.ReLU())\n",
        "    self.fc2 = t.nn.Sequential(t.nn.Linear(200, 100), t.nn.ReLU())\n",
        "    self.fc3 = t.nn.Sequential(t.nn.Linear(100, 20), t.nn.ReLU())\n",
        "    self.fc4 = t.nn.Linear(20, 10)\n",
        "  \n",
        "  def forward(self):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  \n",
        "class conv_net(t.nn.Module):\n",
        "  \"\"\"\n",
        "  卷积网络，需要先将数据转为2维图片形式\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(conv_net,self).__init__()\n",
        "    self.conv1 = t.nn.Sequential(\n",
        "                t.nn.Conv2d(1, 10, 5, 1, 1),\n",
        "                t.nn.MaxPool2d(2),\n",
        "                t.nn.ReLU(),\n",
        "#         加入BatchNorm2d的原因：\n",
        "#         首先，在进行训练之前，一般要对数据做归一化，是其分布一致，\n",
        "#         但是在深度神经网络训练过程中，通常以送入网络的每一个batch训练，\n",
        "#         这样每个batch具有不同的分布；此外为了解决internal covarivate shift 问题，\n",
        "#         所谓的internal covarivate shift就是数据迁移。\n",
        "#         这个问题定义是随着batch normalization这篇论文提出的，在训练过程中，\n",
        "#         数据分布是会变化的，对下一层网络的学习带来困难。\n",
        "#         所以batch normalization就是强行将数据拉回到均值为0，方差为1的正太分布上，\n",
        "#         这样不仅数据分布一致，而且避免发生梯度消失。\n",
        "                t.nn.BatchNorm2d(10))\n",
        "    self.conv2 = t.nn.Sequential(\n",
        "                 t.nn.Conv2d(10, 20, 5, 1, 1),\n",
        "                 t.nn.MaxPool2d(2),\n",
        "                 t.nn.ReLU(),\n",
        "                 t.nn.BatchNorm2d(20))\n",
        "    \n",
        "    self.fc1 = t.nn.Sequential(\n",
        "                t.nn.Linear(500, 60),\n",
        "                t.nn.Dropout(0.5),\n",
        "                t.nn.ReLU())\n",
        "    \n",
        "    self.fc2 = t.nn.Sequential(\n",
        "               t.nn.Linear(60, 20),\n",
        "               t.nn.Dropout(0.5),\n",
        "               t.nn.ReLU())\n",
        "    \n",
        "    self.fc3 = t.nn.Linear(20, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.fc1(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.fc3(x)\n",
        "      \n",
        "      return x\n",
        "    \n",
        "    \n",
        "    \n",
        "class AlexNet(t.nn.Module):\n",
        "  \"\"\"\n",
        "  类似于AlexNet的神经网络\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(AlexNet, self).__init__()\n",
        "    self.features = t.nn.Sequential(\n",
        "                    t.nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.MaxPool2d(kernel_size=3, stride=1),\n",
        "                    t.nn.Conv2d(64, 192, kernel_size=3, padding=2),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                    t.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.MaxPool2d(kernel_size=3, stride=2),)\n",
        "   \n",
        "    self.classifier = t.nn.Sequential(\n",
        "                    t.nn.Dropout(),\n",
        "                    t.nn.Linear(256 * 6 * 6, 4096),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.Dropout(),\n",
        "                    t.nn.Linear(4096, 4096),\n",
        "                    t.nn.ReLU(inplace=True),\n",
        "                    t.nn.Linear(4096, num_classes),\n",
        "                    )\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.features(x)\n",
        "      print(x)\n",
        "      x = x.view(x.size(0), 256 * 6 * 6)\n",
        "      print(x.shape)\n",
        "      x = self.classifier(x)\n",
        "      \n",
        "      return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IooNP9oyo5c_",
        "colab_type": "text"
      },
      "source": [
        "[internal covarivate shift详解](https://blog.csdn.net/mao_xiao_feng/article/details/54317852)\n",
        "\n",
        "\n",
        "[batch normalization详解](https://blog.csdn.net/liuxiao214/article/details/81037416)\n",
        "\n",
        "[梯度消失详解](https://www.cnblogs.com/mengnan/p/9480804.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJCLRf3ejUyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import torch as t\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "from mnist_models import conv_net,to_image,fc_net,AlexNet\n",
        "import signal\n",
        "\n",
        "# 设置模型参数\n",
        "TYPE = 'cla'\n",
        "METHOD = 'conv'\n",
        "EPOCHS = 400\n",
        "BATCH_SIZE = 500\n",
        "LR = 0.001\n",
        "\n",
        "# 读取数据\n",
        "train = pd.read_csv('./data/train.csv')\n",
        "data = train.drop('label',axis=1)\n",
        "test = pd.read_csv('./data/test.csv')\n",
        "test_data = t.from_numpy(test.values).float()\n",
        "data = data.values\n",
        "\n",
        "# 标签与自变量处理\n",
        "y = train['label'].values\n",
        "y = t.from_numpy(y).long()\n",
        "data = t.from_numpy(data).float()\n",
        "data,y = Variable(data),Variable(y)\n",
        "\n",
        "# 初始化模型\n",
        "if METHOD == 'conv':\n",
        "    data = to_image(data) # 将数据转为二维\n",
        "    test_data = to_image(test_data)\n",
        "    net = conv_net()\n",
        "elif METHOD == 'fc':\n",
        "    net = fc_net()\n",
        "elif METHOD == 'res':\n",
        "    # 使用resnet18进行迁移学习，微调参数，如果冻结参数，将resnet作为特征选择器的话，训练速度更快。\n",
        "    # 因为resnet参数过多，不建议使用CPU运算，使用Xeon E5620一个EPOCH要训练三个小时\n",
        "    data = to_image(data)\n",
        "    test_data = to_image(test_data)\n",
        "    net = models.resnet18(pretrained=True)\n",
        "    # 固定参数\n",
        "    for p in net.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # 因为MNIST图片是单通道，并且尺寸较小，所以需要对resnet进行一些细节修改\n",
        "    net.conv1 = t.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=3,\n",
        "                           bias=False)\n",
        "    net.maxpool = t.nn.MaxPool2d(kernel_size=2, stride=1, padding=1)\n",
        "    net.avgpool = t.nn.AvgPool2d(5, stride=1)\n",
        "\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = t.nn.Linear(num_ftrs,10)\n",
        "\n",
        "elif METHOD == 'alex':\n",
        "    data = to_image(data)\n",
        "    test_data = to_image(test_data)\n",
        "    net = AlexNet()\n",
        "\n",
        "else:\n",
        "    raise Exception(\"Wrong Method!\")\n",
        "\n",
        "\n",
        "# 如果模型文件存在则尝试加载模型参数\n",
        "if os.path.exists('H:/learning_notes/MNIST/%s.pth' % METHOD):\n",
        "    try:\n",
        "        net.load_state_dict(t.load('H:/learning_notes/MNIST/%s.pth' % METHOD))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Parameters Error\")\n",
        "\n",
        "# 定义模型代价函数\n",
        "if TYPE == 'reg':\n",
        "    criterion = t.nn.MSELoss()\n",
        "elif TYPE == 'cla':\n",
        "    criterion = t.nn.CrossEntropyLoss()\n",
        "else:\n",
        "    raise Exception(\"Wrong Type!\")\n",
        "\n",
        "# 定义优化器\n",
        "if METHOD == 'res':\n",
        "    # 如果是用的resnet，则只训练最后的全连接层的参数\n",
        "    optim = t.optim.Adam(net.fc.parameters(),lr = 0.001,weight_decay=0.0)\n",
        "else:\n",
        "    optim = t.optim.Adam(net.parameters(),lr=0.001,weight_decay=0.0)\n",
        "\n",
        "\n",
        "# plt.ion() # 用于绘制动态图\n",
        "# losses = []\n",
        "\n",
        "# 用于捕捉KeyboardInterrupt错误，效果比try except好得多\n",
        "# 可以人为终止训练，并将训练得到的参数保存下来，实现断点训练\n",
        "def exit(signum, frame):\n",
        "    print(\"Model Saved\")\n",
        "    t.save(net.state_dict(), 'H:/learning_notes/MNIST/%s.pth' % METHOD)\n",
        "    raise KeyboardInterrupt\n",
        "\n",
        "signal.signal(signal.SIGINT, exit)\n",
        "signal.signal(signal.SIGTERM, exit)\n",
        "\n",
        "\n",
        "# 开始训练\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    index = 0\n",
        "    if epoch % 100 == 0:\n",
        "        for param_group in optim.param_groups:\n",
        "            LR = LR * 0.9\n",
        "            param_group['lr'] = LR\n",
        "    for i in tqdm(range(int(len(data)/BATCH_SIZE)),total=int(len(data)/BATCH_SIZE)):\n",
        "\n",
        "        batch_x = data[index:index + BATCH_SIZE]\n",
        "        batch_y = y[index:index + BATCH_SIZE]\n",
        "        prediction = net.forward(batch_x)\n",
        "        loss = criterion(prediction, batch_y)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        index += BATCH_SIZE  # 进入下一个batch\n",
        "        # if loss <= 0.3:\n",
        "            # losses.append(loss)\n",
        "        # plt.plot(losses)\n",
        "        # plt.pause(0.001)\n",
        "\n",
        "        print(loss)\n",
        "t.save(net.state_dict(),'H:/learning_notes/MNIST/%s.pth' % METHOD)\n",
        "# plt.ioff()\n",
        "submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
        "\n",
        "print('=======Predicting========')\n",
        "\n",
        "# 切换成验证模式，验证模式下DROPOUT将不起作用\n",
        "net.eval()\n",
        "\n",
        "test_data = Variable(test_data)\n",
        "\n",
        "result = t.Tensor()\n",
        "\n",
        "index = 0\n",
        "\n",
        "# 分段进行预测，节省内存\n",
        "for i in tqdm(range(int(test_data.shape[0]/BATCH_SIZE)),total=int(test_data.shape[0]/BATCH_SIZE)):\n",
        "    label_prediction = net(test_data[index:index+BATCH_SIZE])\n",
        "    index += BATCH_SIZE\n",
        "    result = t.cat((result,label_prediction),0)\n",
        "\n",
        "# 结果处理\n",
        "if TYPE == 'cla':\n",
        "    _,submission['Label'] = t.max(result.data,1) # t.max返回一个元祖，第一个元素是最大元素值，第二个元素是最大元素位置\n",
        "elif TYPE == 'reg':\n",
        "    submission['Label'] = submission['Label'].astype('int')\n",
        "    submission['Label'] = submission['Label'].apply(lambda x:9 if x>= 10 else x)\n",
        "\n",
        "\n",
        "submission.to_csv(\"submission.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}